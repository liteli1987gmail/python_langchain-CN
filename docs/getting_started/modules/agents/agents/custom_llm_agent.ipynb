{"cells": [{"cell_type": "markdown", "id": "ba5f8741", "metadata": {}, "source": ["# \u81ea\u5b9a\u4e49 LLM \u4ee3\u7406\n", "\n", "\u672c\u6587\u6863\u5c06\u4ecb\u7ecd\u5982\u4f55\u521b\u5efa\u81ea\u5b9a\u4e49 LLM \u4ee3\u7406\u3002\n", "\n", "LLM \u4ee3\u7406\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\n", "\n", "- PromptTemplate: \u8fd9\u662f\u4e00\u4e2a\u63d0\u793a\u6a21\u677f\uff0c\u7528\u4e8e\u6307\u5bfc\u8bed\u8a00\u6a21\u578b\u7684\u64cd\u4f5c\n", "- LLM: \u8fd9\u662f\u4e3a\u4ee3\u7406\u63d0\u4f9b\u52a8\u529b\u7684\u8bed\u8a00\u6a21\u578b\n", "- `stop` sequence: \u4e00\u65e6\u53d1\u73b0\u8be5\u5b57\u7b26\u4e32\uff0c\u5373\u6307\u793a LLM \u505c\u6b62\u751f\u6210\n", "- OutputParser: \u8fd9\u51b3\u5b9a\u4e86\u5982\u4f55\u89e3\u6790 LLMOutput \u4e3a AgentAction \u6216 AgentFinish \u5bf9\u8c61\n", "\n", "\n", "LLMAgent \u7528\u4e8e AgentExecutor \u4e2d\u3002\u8be5 AgentExecutor \u4e3b\u8981\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5faa\u73af\uff1a\n", "1. \u5c06\u7528\u6237\u8f93\u5165\u548c\u6240\u6709\u5148\u524d\u6b65\u9aa4\u4f20\u9012\u7ed9\u4ee3\u7406\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a LLMAgent\uff09\n", "2. \u5982\u679c\u4ee3\u7406\u8fd4\u56de\u4e00\u4e2a `AgentFinish`\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\u7ed9\u7528\u6237\n", "3. \u5982\u679c\u4ee3\u7406\u8fd4\u56de\u4e00\u4e2a `AgentAction`\uff0c\u5219\u4f7f\u7528\u5b83\u6765\u8c03\u7528\u5de5\u5177\u5e76\u83b7\u53d6\u4e00\u4e2a `Observation`\n", "4. \u91cd\u590d\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u5c06 `AgentAction` \u548c `Observation` \u4f20\u9012\u56de\u4ee3\u7406\uff0c\u76f4\u5230\u53d1\u51fa\u4e00\u4e2a `AgentFinish`\n", "    \n", "\u201cAgentAction\u201d \u662f\u4e00\u4e2a\u54cd\u5e94\uff0c\u5b83\u7531 \u201caction\u201d \u548c \u201caction_input\u201d \u7ec4\u6210\u3002\u201caction\u201d \u6307\u8981\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177\uff0c\u201caction_input\u201d \u6307\u8981\u4f7f\u7528\u7684\u8f93\u5165\u3002\u8fd8\u53ef\u4ee5\u63d0\u4f9b `log` \u4f5c\u4e3a\u66f4\u591a\u7684\u4e0a\u4e0b\u6587\uff08\u53ef\u7528\u4e8e\u65e5\u5fd7\u8bb0\u5f55\u3001\u8ddf\u8e2a\u7b49\uff09\u3002\n", "\n", "\u201cAgentFinish\u201d \u662f\u4e00\u4e2a\u54cd\u5e94\uff0c\u5305\u542b\u6700\u7ec8\u8981\u53d1\u9001\u56de\u7528\u6237\u7684\u6d88\u606f\u3002\u8fd9\u5e94\u8be5\u7528\u4e8e\u7ed3\u675f\u4ee3\u7406\u8fd0\u884c\u3002\n", "        \n", "\u5728\u672c\u6587\u6863\u4e2d\uff0c\u6211\u4eec\u5c06\u4ecb\u7ecd\u5982\u4f55\u521b\u5efa\u81ea\u5b9a\u4e49 LLM \u4ee3\u7406\u3002"]}, {"cell_type": "markdown", "id": "fea4812c", "metadata": {}, "source": ["## \u8bbe\u7f6e\u73af\u5883\n", "\n", "\u6267\u884c\u5fc5\u8981\u5bfc\u5165\u7b49\u64cd\u4f5c\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "9af9734e", "metadata": {}, "outputs": [], "source": ["from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n", "from langchain.prompts import StringPromptTemplate\n", "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n", "from typing import List, Union\n", "from langchain.schema import AgentAction, AgentFinish\n", "import re"]}, {"cell_type": "markdown", "id": "6df0253f", "metadata": {}, "source": ["## \u8bbe\u7f6e\u5de5\u5177\n", "\n", "\u8bbe\u7f6e\u4ee3\u7406\u53ef\u80fd\u60f3\u8981\u4f7f\u7528\u7684\u4efb\u4f55\u5de5\u5177\u3002\u8fd9\u53ef\u80fd\u9700\u8981\u653e\u5728\u63d0\u793a\u4e2d\uff08\u4ee5\u4fbf\u4ee3\u7406\u77e5\u9053\u8981\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\uff09\u3002"]}, {"cell_type": "code", "execution_count": 2, "id": "becda2a1", "metadata": {}, "outputs": [], "source": ["# Define which tools the agent can use to answer user queries\n", "search = SerpAPIWrapper()\n", "tools = [\n", "    Tool(\n", "        name = \"Search\",\n", "        func=search.run,\n", "        description=\"useful for when you need to answer questions about current events\"\n", "    )\n", "]"]}, {"cell_type": "markdown", "id": "2e7a075c", "metadata": {}, "source": ["## \u63d0\u793a\u6a21\u677f\n", "\n", "\u8fd9\u6307\u5bfc\u4ee3\u7406\u505a\u4ec0\u4e48\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6a21\u677f\u5e94\u8be5\u5305\u62ec\uff1a\n", "    \n", "- `tools`\uff1a\u4ee3\u7406\u53ef\u4ee5\u4f7f\u7528\u54ea\u4e9b\u5de5\u5177\uff0c\u4ee5\u53ca\u4f55\u65f6\u548c\u5982\u4f55\u8c03\u7528\u5b83\u4eec\u3002\n", "- `intermediate_steps`\uff1a\u8fd9\u4e9b\u662f\u5148\u524d\uff08\u201cAgentAction\u201d\uff0c\u201cObservation\u201d\uff09\u5bf9\u7684\u5143\u7ec4\u3002\u901a\u5e38\u4e0d\u4f1a\u76f4\u63a5\u4f20\u9012\u5230\u6a21\u578b\u4e2d\uff0c\u4f46\u63d0\u793a\u6a21\u677f\u4ee5\u7279\u5b9a\u65b9\u5f0f\u683c\u5f0f\u5316\u5b83\u4eec\u3002\n", "- `input`\uff1a\u901a\u7528\u7528\u6237\u8f93\u5165"]}, {"cell_type": "code", "execution_count": 3, "id": "339b1bb8", "metadata": {}, "outputs": [], "source": ["# Set up the base template\n", "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n", "\n", "{tools}\n", "\n", "Use the following format:\n", "\n", "Question: the input question you must answer\n", "Thought: you should always think about what to do\n", "Action: the action to take, should be one of [{tool_names}]\n", "Action Input: the input to the action\n", "Observation: the result of the action\n", "... (this Thought/Action/Action Input/Observation can repeat N times)\n", "Thought: I now know the final answer\n", "Final Answer: the final answer to the original input question\n", "\n", "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n", "\n", "Question: {input}\n", "{agent_scratchpad}\"\"\""]}, {"cell_type": "code", "execution_count": 4, "id": "fd969d31", "metadata": {}, "outputs": [], "source": ["# Set up a prompt template\n", "class CustomPromptTemplate(StringPromptTemplate):\n", "    # The template to use\n", "    template: str\n", "    # The list of tools available\n", "    tools: List[Tool]\n", "    \n", "    def format(self, **kwargs) -> str:\n", "        # Get the intermediate steps (AgentAction, Observation tuples)\n", "        # Format them in a particular way\n", "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n", "        thoughts = \"\"\n", "        for action, observation in intermediate_steps:\n", "            thoughts += action.log\n", "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n", "        # Set the agent_scratchpad variable to that value\n", "        kwargs[\"agent_scratchpad\"] = thoughts\n", "        # Create a tools variable from the list of tools provided\n", "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n", "        # Create a list of tool names for the tools provided\n", "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n", "        return self.template.format(**kwargs)"]}, {"cell_type": "code", "execution_count": 5, "id": "798ef9fb", "metadata": {}, "outputs": [], "source": ["prompt = CustomPromptTemplate(\n", "    template=template,\n", "    tools=tools,\n", "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n", "    # This includes the `intermediate_steps` variable because that is needed\n", "    input_variables=[\"input\", \"intermediate_steps\"]\n", ")"]}, {"cell_type": "markdown", "id": "ef3a1af3", "metadata": {}, "source": ["## \u8f93\u51fa\u89e3\u6790\u5668\n", "\n", "\u8f93\u51fa\u89e3\u6790\u5668\u8d1f\u8d23\u5c06 LLM \u8f93\u51fa\u89e3\u6790\u4e3a\u201cAgentAction\u201d\u548c\u201cAgentFinish\u201d\u3002\u8fd9\u901a\u5e38\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u4f7f\u7528\u7684\u63d0\u793a\u3002\n", "\n", "\u8fd9\u662f\u60a8\u53ef\u4ee5\u66f4\u6539\u89e3\u6790\u4ee5\u8fdb\u884c\u91cd\u8bd5\u3001\u5904\u7406\u7a7a\u683c\u7b49\u64cd\u4f5c\u7684\u4f4d\u7f6e"]}, {"cell_type": "code", "execution_count": 6, "id": "7c6fe0d3", "metadata": {}, "outputs": [], "source": ["class CustomOutputParser(AgentOutputParser):\n", "    \n", "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n", "        # Check if agent should finish\n", "        if \"Final Answer:\" in llm_output:\n", "            return AgentFinish(\n", "                # Return values is generally always a dictionary with a single `output` key\n", "                # It is not recommended to try anything else at the moment :)\n", "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n", "                log=llm_output,\n", "            )\n", "        # Parse out the action and action input\n", "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n", "        match = re.search(regex, llm_output, re.DOTALL)\n", "        if not match:\n", "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n", "        action = match.group(1).strip()\n", "        action_input = match.group(2)\n", "        # Return the action and action input\n", "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"]}, {"cell_type": "code", "execution_count": 7, "id": "d278706a", "metadata": {}, "outputs": [], "source": ["output_parser = CustomOutputParser()"]}, {"cell_type": "markdown", "id": "170587b1", "metadata": {}, "source": ["## \u8bbe\u7f6e LLM\n", "\n", "\u9009\u62e9\u8981\u4f7f\u7528\u7684 LLM\uff01"]}, {"cell_type": "code", "execution_count": 8, "id": "f9d4c374", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(temperature=0)"]}, {"cell_type": "markdown", "id": "caeab5e4", "metadata": {}, "source": ["## \u5b9a\u4e49\u505c\u6b62\u5e8f\u5217\n", "\n", "\u8fd9\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u544a\u8bc9 LLM \u4f55\u65f6\u505c\u6b62\u751f\u6210\u3002\n", "\n", "\u8fd9\u4e25\u91cd\u53d6\u51b3\u4e8e\u60a8\u4f7f\u7528\u7684\u63d0\u793a\u548c\u6a21\u578b\u3002\u901a\u5e38\uff0c\u60a8\u5e0c\u671b\u8fd9\u662f\u60a8\u5728\u63d0\u793a\u4e2d\u7528\u4e8e\u8868\u793a\u201cObservation\u201d\u5f00\u5934\u7684\u4ee4\u724c\uff08\u5426\u5219\uff0cLLM \u53ef\u80fd\u4f1a\u4e3a\u60a8\u4ea7\u751f\u5e7b\u89c9\uff09\u3002"]}, {"cell_type": "markdown", "id": "34be9f65", "metadata": {}, "source": ["## \u8bbe\u7f6e\u4ee3\u7406\n", "\n", "\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u5c06\u6240\u6709\u5185\u5bb9\u7ec4\u5408\u8d77\u6765\u8bbe\u7f6e\u4ee3\u7406"]}, {"cell_type": "code", "execution_count": 9, "id": "9b1cc2a2", "metadata": {}, "outputs": [], "source": ["# LLM chain consisting of the LLM and a prompt\n", "llm_chain = LLMChain(llm=llm, prompt=prompt)"]}, {"cell_type": "code", "execution_count": 10, "id": "e4f5092f", "metadata": {}, "outputs": [], "source": ["tool_names = [tool.name for tool in tools]\n", "agent = LLMSingleActionAgent(\n", "    llm_chain=llm_chain, \n", "    output_parser=output_parser,\n", "    stop=[\"\\nObservation:\"], \n", "    allowed_tools=tool_names\n", ")"]}, {"cell_type": "markdown", "id": "aa8a5326", "metadata": {}, "source": ["## \u4f7f\u7528\u4ee3\u7406\n", "\n", "\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5b83\u4e86\uff01"]}, {"cell_type": "code", "execution_count": 11, "id": "490604e9", "metadata": {}, "outputs": [], "source": ["agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"]}, {"cell_type": "code", "execution_count": 12, "id": "653b1617", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n", "\u001b[32;1m\u001b[1;3mThought: I need to find out the population of Canada in 2023\n", "Action: Search\n", "Action Input: Population of Canada in 2023\u001b[0m\n", "\n", "Observation:\u001b[36;1m\u001b[1;3mThe current population of Canada is 38,658,314 as of Wednesday, April 12, 2023, based on Worldometer elaboration of the latest United Nations data.\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n", "Final Answer: Arrr, there be 38,658,314 people livin' in Canada as of 2023!\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\"Arrr, there be 38,658,314 people livin' in Canada as of 2023!\""]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["agent_executor.run(\"How many people live in canada as of 2023?\")"]}, {"cell_type": "markdown", "id": "d5b4a078", "metadata": {}, "source": ["## \u6dfb\u52a0\u8bb0\u5fc6\n", "\n", "\u5982\u679c\u60a8\u8981\u5c06\u8bb0\u5fc6\u6dfb\u52a0\u5230\u4ee3\u7406\u4e2d\uff0c\u60a8\u9700\u8981\uff1a\n", "\n", "1. \u5728\u81ea\u5b9a\u4e49\u63d0\u793a\u4e2d\u4e3a chat_history \u6dfb\u52a0\u4e00\u4e2a\u4f4d\u7f6e\n", "2. \u4e3a\u4ee3\u7406\u6267\u884c\u5668\u6dfb\u52a0\u5185\u5b58\u5bf9\u8c61\u3002"]}, {"cell_type": "code", "execution_count": 29, "id": "94fffda1", "metadata": {}, "outputs": [], "source": ["# Set up the base template\n", "template_with_history = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n", "\n", "{tools}\n", "\n", "Use the following format:\n", "\n", "Question: the input question you must answer\n", "Thought: you should always think about what to do\n", "Action: the action to take, should be one of [{tool_names}]\n", "Action Input: the input to the action\n", "Observation: the result of the action\n", "... (this Thought/Action/Action Input/Observation can repeat N times)\n", "Thought: I now know the final answer\n", "Final Answer: the final answer to the original input question\n", "\n", "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n", "\n", "Previous conversation history:\n", "{history}\n", "\n", "New question: {input}\n", "{agent_scratchpad}\"\"\""]}, {"cell_type": "code", "execution_count": 30, "id": "f58488d7", "metadata": {}, "outputs": [], "source": ["prompt_with_history = CustomPromptTemplate(\n", "    template=template_with_history,\n", "    tools=tools,\n", "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n", "    # This includes the `intermediate_steps` variable because that is needed\n", "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n", ")"]}, {"cell_type": "code", "execution_count": 31, "id": "d28d4b5a", "metadata": {}, "outputs": [], "source": ["llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)"]}, {"cell_type": "code", "execution_count": 32, "id": "3e37b32a", "metadata": {}, "outputs": [], "source": ["tool_names = [tool.name for tool in tools]\n", "agent = LLMSingleActionAgent(\n", "    llm_chain=llm_chain, \n", "    output_parser=output_parser,\n", "    stop=[\"\\nObservation:\"], \n", "    allowed_tools=tool_names\n", ")"]}, {"cell_type": "code", "execution_count": 33, "id": "97ea1bce", "metadata": {}, "outputs": [], "source": ["from langchain.memory import ConversationBufferWindowMemory"]}, {"cell_type": "code", "execution_count": 42, "id": "b5ad69ce", "metadata": {}, "outputs": [], "source": ["memory=ConversationBufferWindowMemory(k=2)"]}, {"cell_type": "code", "execution_count": 43, "id": "b7b5c9b1", "metadata": {}, "outputs": [], "source": ["agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"]}, {"cell_type": "code", "execution_count": 44, "id": "5ec4c39b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n", "\u001b[32;1m\u001b[1;3mThought: I need to find out the population of Canada in 2023\n", "Action: Search\n", "Action Input: Population of Canada in 2023\u001b[0m\n", "\n", "Observation:\u001b[36;1m\u001b[1;3mThe current population of Canada is 38,658,314 as of Wednesday, April 12, 2023, based on Worldometer elaboration of the latest United Nations data.\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n", "Final Answer: Arrr, there be 38,658,314 people livin' in Canada as of 2023!\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\"Arrr, there be 38,658,314 people livin' in Canada as of 2023!\""]}, "execution_count": 44, "metadata": {}, "output_type": "execute_result"}], "source": ["agent_executor.run(\"How many people live in canada as of 2023?\")"]}, {"cell_type": "code", "execution_count": 45, "id": "b2ba45bb", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n", "\u001b[32;1m\u001b[1;3mThought: I need to find out how many people live in Mexico.\n", "Action: Search\n", "Action Input: How many people live in Mexico as of 2023?\u001b[0m\n", "\n", "Observation:\u001b[36;1m\u001b[1;3mThe current population of Mexico is 132,679,922 as of Tuesday, April 11, 2023, based on Worldometer elaboration of the latest United Nations data. Mexico 2020 ...\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n", "Final Answer: Arrr, there be 132,679,922 people livin' in Mexico as of 2023!\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\"Arrr, there be 132,679,922 people livin' in Mexico as of 2023!\""]}, "execution_count": 45, "metadata": {}, "output_type": "execute_result"}], "source": ["agent_executor.run(\"how about in mexico?\")"]}, {"cell_type": "code", "execution_count": null, "id": "bd820a7a", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}, "vscode": {"interpreter": {"hash": "18784188d7ecd866c0586ac068b02361a6896dc3a29b64f5cc957f09c590acef"}}}, "nbformat": 4, "nbformat_minor": 5}