{"cells": [{"cell_type": "markdown", "id": "593f7553-7038-498e-96d4-8255e5ce34f0", "metadata": {}, "source": ["# \u9762\u5411\u94fe\u7684\u5f02\u6b65 API\n", "\n", "LangChain\u4f7f\u7528[asyncio](https://docs.python.org/3/library/asyncio.html)\u5e93\uff0c\u63d0\u4f9b\u4e86\u5bf9\u94fe\u7684\u5f02\u6b65\u652f\u6301\u3002\n", "\n", "\u5f02\u6b65\u65b9\u6cd5\u76ee\u524d\u5728`LLMChain`\uff08\u901a\u8fc7`arun`\uff0c`apredict`\uff0c`acall`\uff09\u548c`LLMMathChain`\uff08\u901a\u8fc7`arun`\u548c`acall`\uff09\u3001`ChatVectorDBChain`\u4ee5\u53ca[QA chains](../index_examples/question_answering.ipynb)\u4e2d\u53d7\u652f\u6301\u3002\u5bf9\u4e8e\u5176\u4ed6\u94fe\u7684\u5f02\u6b65\u652f\u6301\u5df2\u5728\u8def\u4e0a\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "c19c736e-ca74-4726-bb77-0a849bcc2960", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "BrightSmile Toothpaste Company\n", "\n", "\n", "BrightSmile Toothpaste Co.\n", "\n", "\n", "BrightSmile Toothpaste\n", "\n", "\n", "Gleaming Smile Inc.\n", "\n", "\n", "SparkleSmile Toothpaste\n", "\u001b[1mConcurrent executed in 1.54 seconds.\u001b[0m\n", "\n", "\n", "BrightSmile Toothpaste Co.\n", "\n", "\n", "MintyFresh Toothpaste Co.\n", "\n", "\n", "SparkleSmile Toothpaste.\n", "\n", "\n", "Pearly Whites Toothpaste Co.\n", "\n", "\n", "BrightSmile Toothpaste.\n", "\u001b[1mSerial executed in 6.38 seconds.\u001b[0m\n"]}], "source": ["import asyncio\n", "import time\n", "\n", "from langchain.llms import OpenAI\n", "from langchain.prompts import PromptTemplate\n", "from langchain.chains import LLMChain\n", "\n", "\n", "def generate_serially():\n", "    llm = OpenAI(temperature=0.9)\n", "    prompt = PromptTemplate(\n", "        input_variables=[\"product\"],\n", "        template=\"What is a good name for a company that makes {product}?\",\n", "    )\n", "    chain = LLMChain(llm=llm, prompt=prompt)\n", "    for _ in range(5):\n", "        resp = chain.run(product=\"toothpaste\")\n", "        print(resp)\n", "\n", "\n", "async def async_generate(chain):\n", "    resp = await chain.arun(product=\"toothpaste\")\n", "    print(resp)\n", "\n", "\n", "async def generate_concurrently():\n", "    llm = OpenAI(temperature=0.9)\n", "    prompt = PromptTemplate(\n", "        input_variables=[\"product\"],\n", "        template=\"What is a good name for a company that makes {product}?\",\n", "    )\n", "    chain = LLMChain(llm=llm, prompt=prompt)\n", "    tasks = [async_generate(chain) for _ in range(5)]\n", "    await asyncio.gather(*tasks)\n", "\n", "s = time.perf_counter()\n", "# If running this outside of Jupyter, use asyncio.run(generate_concurrently())\n", "await generate_concurrently()\n", "elapsed = time.perf_counter() - s\n", "print('\\033[1m' + f\"Concurrent executed in {elapsed:0.2f} seconds.\" + '\\033[0m')\n", "\n", "s = time.perf_counter()\n", "generate_serially()\n", "elapsed = time.perf_counter() - s\n", "print('\\033[1m' + f\"Serial executed in {elapsed:0.2f} seconds.\" + '\\033[0m')\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}