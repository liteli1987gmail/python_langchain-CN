{"cells": [{"cell_type": "markdown", "id": "00695447", "metadata": {}, "source": ["\u5982\u4f55\u5411LLMChain\u6dfb\u52a0\u5185\u5b58", "\u672c\u7b14\u8bb0\u672c\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528Memory\u7c7b\u4e0eLLMChain\u914d\u5408\u4f7f\u7528\u3002\u4e3a\u4e86\u6f14\u793a\uff0c\u6211\u4eec\u5c06\u6dfb\u52a0ConversationBufferMemory\u7c7b\uff0c\u4f46\u5b9e\u9645\u4e0a\u53ef\u4ee5\u662f\u4efb\u4f55\u5185\u5b58\u7c7b\u3002", "# How to add Memory to an LLMChain\n"]}, {"cell_type": "code", "execution_count": 1, "id": "9f1aaf47", "metadata": {}, "outputs": [], "source": ["from langchain.memory import ConversationBufferMemory\n", "from langchain import OpenAI, LLMChain, PromptTemplate"]}, {"cell_type": "markdown", "id": "4b066ced", "metadata": {}, "source": ["\u6700\u91cd\u8981\u7684\u4e00\u6b65\u662f\u6b63\u786e\u8bbe\u7f6e\u63d0\u793a\u3002\u5728\u4e0b\u9762\u7684\u63d0\u793a\u4e2d\uff0c\u6211\u4eec\u6709\u4e24\u4e2a\u8f93\u5165\u952e\uff1a\u4e00\u4e2a\u7528\u4e8e\u5b9e\u9645\u8f93\u5165\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u6765\u81eaMemory\u7c7b\u7684\u8f93\u5165\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u786e\u4fddPromptTemplate\u548cConversationBufferMemory\u4e2d\u7684\u952e\u5339\u914d\uff08`chat_history`\uff09\u3002", "The most important step is setting up the prompt correctly. In the below prompt, we have two input keys: one for the actual input, another for the input from the Memory class. Importantly, we make sure the keys in the PromptTemplate and the ConversationBufferMemory match up (`chat_history`)."]}, {"cell_type": "code", "execution_count": 2, "id": "e5501eda", "metadata": {}, "outputs": [], "source": ["template = \"\"\"You are a chatbot having a conversation with a human.\n", "\n", "{chat_history}\n", "Human: {human_input}\n", "Chatbot:\"\"\"\n", "\n", "prompt = PromptTemplate(\n", "    input_variables=[\"chat_history\", \"human_input\"], \n", "    template=template\n", ")\n", "memory = ConversationBufferMemory(memory_key=\"chat_history\")"]}, {"cell_type": "code", "execution_count": 3, "id": "f6566275", "metadata": {}, "outputs": [], "source": ["llm_chain = LLMChain(\n", "    llm=OpenAI(), \n", "    prompt=prompt, \n", "    verbose=True, \n", "    memory=memory,\n", ")"]}, {"cell_type": "code", "execution_count": 4, "id": "e2b189dc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n", "\n", "\n", "Human: Hi there my friend\n", "Chatbot:\u001b[0m\n", "\n", "\u001b[1m> Finished LLMChain chain.\u001b[0m\n"]}, {"data": {"text/plain": ["' Hi there, how are you doing today?'"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["llm_chain.predict(human_input=\"Hi there my friend\")"]}, {"cell_type": "code", "execution_count": 5, "id": "a902729f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n", "\n", "\n", "Human: Hi there my friend\n", "AI:  Hi there, how are you doing today?\n", "Human: Not too bad - how are you?\n", "Chatbot:\u001b[0m\n", "\n", "\u001b[1m> Finished LLMChain chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" I'm doing great, thank you for asking!\""]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["llm_chain.predict(human_input=\"Not too bad - how are you?\")"]}, {"cell_type": "code", "execution_count": null, "id": "ae5309bb", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}