{"cells": [{"cell_type": "markdown", "id": "94e33ebe", "metadata": {}, "source": ["# \u5982\u4f55\u521b\u5efa\u81ea\u5b9a\u4e49\u5185\u5b58\u7c7b\n", "\u867d\u7136\u5728LangChain\u4e2d\u6709\u51e0\u79cd\u9884\u5b9a\u4e49\u7684\u5185\u5b58\u7c7b\u578b\uff0c\u4f46\u4f60\u5f88\u53ef\u80fd\u60f3\u8981\u6dfb\u52a0\u81ea\u5df1\u7684\u5185\u5b58\u7c7b\u578b\uff0c\u4ee5\u4f7f\u5176\u6700\u9002\u5408\u4f60\u7684\u5e94\u7528\u7a0b\u5e8f\u3002\u672c\u7b14\u8bb0\u672c\u4ecb\u7ecd\u5982\u4f55\u5b9e\u73b0\u3002\n"]}, {"cell_type": "markdown", "id": "bdfd0305", "metadata": {}, "source": ["\u5728\u672c\u7b14\u8bb0\u672c\u4e2d\uff0c\u6211\u4eec\u5c06\u5411`ConversationChain`\u6dfb\u52a0\u81ea\u5b9a\u4e49\u5185\u5b58\u7c7b\u578b\u3002\u4e3a\u4e86\u6dfb\u52a0\u81ea\u5b9a\u4e49\u5185\u5b58\u7c7b\uff0c\u6211\u4eec\u9700\u8981\u5bfc\u5165\u57fa\u672c\u5185\u5b58\u7c7b\u5e76\u8fdb\u884c\u5b50\u7c7b\u5316\u3002\n"]}, {"cell_type": "code", "execution_count": 1, "id": "6d787ef2", "metadata": {}, "outputs": [], "source": ["from langchain import OpenAI, ConversationChain\n", "from langchain.schema import BaseMemory\n", "from pydantic import BaseModel\n", "from typing import List, Dict, Any"]}, {"cell_type": "markdown", "id": "9489e5e1", "metadata": {}, "source": ["\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c06\u7f16\u5199\u4e00\u4e2a\u4f7f\u7528spacy\u63d0\u53d6\u5b9e\u4f53\u5e76\u5c06\u5173\u4e8e\u5b83\u4eec\u7684\u4fe1\u606f\u4fdd\u5b58\u5728\u7b80\u5355\u54c8\u5e0c\u8868\u4e2d\u7684\u81ea\u5b9a\u4e49\u5185\u5b58\u7c7b\u3002\u7136\u540e\uff0c\u5728\u5bf9\u8bdd\u671f\u95f4\uff0c\u6211\u4eec\u5c06\u67e5\u770b\u8f93\u5165\u6587\u672c\uff0c\u63d0\u53d6\u4efb\u4f55\u5b9e\u4f53\uff0c\u5e76\u5c06\u4efb\u4f55\u6709\u5173\u5b83\u4eec\u7684\u4fe1\u606f\u653e\u5165\u4e0a\u4e0b\u6587\u4e2d\u3002\n", "\n", "* \u8bf7\u6ce8\u610f\uff0c\u6b64\u5b9e\u73b0\u975e\u5e38\u7b80\u5355\u548c\u8106\u5f31\uff0c\u53ef\u80fd\u65e0\u6cd5\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u4f7f\u7528\u3002\u5b83\u7684\u76ee\u7684\u662f\u5c55\u793a\u60a8\u53ef\u4ee5\u6dfb\u52a0\u81ea\u5b9a\u4e49\u5185\u5b58\u5b9e\u73b0\u3002\n", "\n", "\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528spacy\u3002\n"]}, {"cell_type": "code", "execution_count": null, "id": "48a5dd13", "metadata": {}, "outputs": [], "source": ["# !pip install spacy\n", "# !python -m spacy download en_core_web_lg"]}, {"cell_type": "code", "execution_count": 5, "id": "ff065f58", "metadata": {}, "outputs": [], "source": ["import spacy\n", "nlp = spacy.load('en_core_web_lg')"]}, {"cell_type": "code", "execution_count": 9, "id": "1d45d429", "metadata": {}, "outputs": [], "source": ["class SpacyEntityMemory(BaseMemory, BaseModel):\n", "    \"\"\"Memory class for storing information about entities.\"\"\"\n", "\n", "    # Define dictionary to store information about entities.\n", "    entities: dict = {}\n", "    # Define key to pass information about entities into prompt.\n", "    memory_key: str = \"entities\"\n", "        \n", "    def clear(self):\n", "        self.entities = {}\n", "\n", "    @property\n", "    def memory_variables(self) -> List[str]:\n", "        \"\"\"Define the variables we are providing to the prompt.\"\"\"\n", "        return [self.memory_key]\n", "\n", "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n", "        \"\"\"Load the memory variables, in this case the entity key.\"\"\"\n", "        # Get the input text and run through spacy\n", "        doc = nlp(inputs[list(inputs.keys())[0]])\n", "        # Extract known information about entities, if they exist.\n", "        entities = [self.entities[str(ent)] for ent in doc.ents if str(ent) in self.entities]\n", "        # Return combined information about entities to put into context.\n", "        return {self.memory_key: \"\\n\".join(entities)}\n", "\n", "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n", "        \"\"\"Save context from this conversation to buffer.\"\"\"\n", "        # Get the input text and run through spacy\n", "        text = inputs[list(inputs.keys())[0]]\n", "        doc = nlp(text)\n", "        # For each entity that was mentioned, save this information to the dictionary.\n", "        for ent in doc.ents:\n", "            ent_str = str(ent)\n", "            if ent_str in self.entities:\n", "                self.entities[ent_str] += f\"\\n{text}\"\n", "            else:\n", "                self.entities[ent_str] = text"]}, {"cell_type": "markdown", "id": "429ba264", "metadata": {}, "source": ["\u73b0\u5728\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u63d0\u793a\uff0c\u5b83\u63a5\u6536\u6709\u5173\u5b9e\u4f53\u4ee5\u53ca\u7528\u6237\u8f93\u5165\u7684\u4fe1\u606f\u3002"]}, {"cell_type": "code", "execution_count": 10, "id": "c05159b6", "metadata": {}, "outputs": [], "source": ["from langchain.prompts.prompt import PromptTemplate\n", "\n", "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n", "\n", "Relevant entity information:\n", "{entities}\n", "\n", "Conversation:\n", "Human: {input}\n", "AI:\"\"\"\n", "prompt = PromptTemplate(\n", "    input_variables=[\"entities\", \"input\"], template=template\n", ")"]}, {"cell_type": "markdown", "id": "db611041", "metadata": {}, "source": ["\u73b0\u5728\uff0c\u6211\u4eec\u628a\u5b83\u4eec\u5168\u90e8\u7ec4\u5408\u8d77\u6765\uff01\n"]}, {"cell_type": "code", "execution_count": 11, "id": "f08dc8ed", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(temperature=0)\n", "conversation = ConversationChain(llm=llm, prompt=prompt, verbose=True, memory=SpacyEntityMemory())"]}, {"cell_type": "markdown", "id": "92a5f685", "metadata": {}, "source": ["\u5728\u7b2c\u4e00\u4e2a\u793a\u4f8b\u4e2d\uff0c\u6ca1\u6709\u5173\u4e8eHarrison\u7684\u5148\u524d\u77e5\u8bc6\uff0c\u201c\u76f8\u5173\u5b9e\u4f53\u4fe1\u606f\u201d\u90e8\u5206\u4e3a\u7a7a\u3002"]}, {"cell_type": "code", "execution_count": 12, "id": "5b96e836", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n", "\n", "Relevant entity information:\n", "\n", "\n", "Conversation:\n", "Human: Harrison likes machine learning\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished ConversationChain chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" That's great to hear! Machine learning is a fascinating field of study. It involves using algorithms to analyze data and make predictions. Have you ever studied machine learning, Harrison?\""]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"Harrison likes machine learning\")"]}, {"cell_type": "markdown", "id": "b1faa743", "metadata": {}, "source": ["\u73b0\u5728\u5728\u7b2c\u4e8c\u4e2a\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5b83\u6536\u96c6\u4e86\u6709\u5173Harrison\u7684\u4fe1\u606f\u3002"]}, {"cell_type": "code", "execution_count": 13, "id": "4bca7070", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n", "\n", "Relevant entity information:\n", "Harrison likes machine learning\n", "\n", "Conversation:\n", "Human: What do you think Harrison's favorite subject in college was?\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished ConversationChain chain.\u001b[0m\n"]}, {"data": {"text/plain": ["' From what I know about Harrison, I believe his favorite subject in college was machine learning. He has expressed a strong interest in the subject and has mentioned it often.'"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"What do you think Harrison's favorite subject in college was?\")"]}, {"cell_type": "markdown", "id": "58b856e3", "metadata": {}, "source": ["\u518d\u6b21\u8bf7\u6ce8\u610f\uff0c\u6b64\u5b9e\u73b0\u975e\u5e38\u7b80\u5355\u548c\u8106\u5f31\uff0c\u53ef\u80fd\u65e0\u6cd5\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u4f7f\u7528\u3002\u5b83\u7684\u76ee\u7684\u662f\u5c55\u793a\u60a8\u53ef\u4ee5\u6dfb\u52a0\u81ea\u5b9a\u4e49\u5185\u5b58\u5b9e\u73b0\u3002\n"]}, {"cell_type": "code", "execution_count": null, "id": "a1994600", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}