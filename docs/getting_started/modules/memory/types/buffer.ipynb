{"cells": [{"cell_type": "markdown", "id": "46196aa3", "metadata": {}, "source": ["# ConversationBufferMemory\n", "\n", "\u672c\u7b14\u8bb0\u672c\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528ConversationBufferMemory\u3002\u8be5\u5b58\u50a8\u5668\u5141\u8bb8\u5b58\u50a8\u6d88\u606f\uff0c\u5e76\u4ece\u4e00\u4e2a\u53d8\u91cf\u4e2d\u63d0\u53d6\u6d88\u606f\u3002\n", "\n", "\u6211\u4eec\u9996\u5148\u53ef\u4ee5\u5c06\u5176\u63d0\u53d6\u4e3a\u5b57\u7b26\u4e32\u3002"]}, {"cell_type": "code", "execution_count": 2, "id": "3bac84f3", "metadata": {}, "outputs": [], "source": ["from langchain.memory import ConversationBufferMemory"]}, {"cell_type": "code", "execution_count": 3, "id": "cef35e7f", "metadata": {}, "outputs": [], "source": ["memory = ConversationBufferMemory()\n", "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})"]}, {"cell_type": "code", "execution_count": 4, "id": "2c9b39af", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: hi\\nAI: whats up'}"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "567f7c16", "metadata": {}, "source": ["\u6211\u4eec\u8fd8\u53ef\u4ee5\u5c06\u5386\u53f2\u8bb0\u5f55\u4f5c\u4e3a\u6d88\u606f\u5217\u8868\u83b7\u53d6(\u5982\u679c\u60a8\u5c06\u5176\u4e0e\u804a\u5929\u6a21\u578b\u4e00\u8d77\u4f7f\u7528\uff0c\u5219\u8fd9\u5f88\u6709\u7528)\u3002"]}, {"cell_type": "code", "execution_count": 5, "id": "a481a415", "metadata": {}, "outputs": [], "source": ["memory = ConversationBufferMemory(return_messages=True)\n", "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})"]}, {"cell_type": "code", "execution_count": 6, "id": "86a56348", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': [HumanMessage(content='hi', additional_kwargs={}),\n", "  AIMessage(content='whats up', additional_kwargs={})]}"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "d051c1da", "metadata": {}, "source": ["## \u5728\u94fe\u4e2d\u4f7f\u7528\n", "\u6700\u540e\uff0c\u8ba9\u6211\u4eec\u770b\u4e00\u4e0b\u5982\u4f55\u5728\u94fe\u4e2d\u4f7f\u7528\u6b64\u529f\u80fd(\u8bbe\u7f6e'verbose=True'\u4ee5\u4fbf\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u63d0\u793a)\u3002"]}, {"cell_type": "code", "execution_count": 15, "id": "54301321", "metadata": {}, "outputs": [], "source": ["from langchain.llms import OpenAI\n", "from langchain.chains import ConversationChain\n", "\n", "\n", "llm = OpenAI(temperature=0)\n", "conversation = ConversationChain(\n", "    llm=llm, \n", "    verbose=True, \n", "    memory=ConversationBufferMemory()\n", ")"]}, {"cell_type": "code", "execution_count": 16, "id": "ae046bff", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "\n", "Human: Hi there!\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" Hi there! It's nice to meet you. How can I help you today?\""]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"Hi there!\")"]}, {"cell_type": "code", "execution_count": 17, "id": "d8e2a6ff", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "Human: Hi there!\n", "AI:  Hi there! It's nice to meet you. How can I help you today?\n", "Human: I'm doing well! Just having a conversation with an AI.\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"]}, {"cell_type": "code", "execution_count": 18, "id": "15eda316", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "Human: Hi there!\n", "AI:  Hi there! It's nice to meet you. How can I help you today?\n", "Human: I'm doing well! Just having a conversation with an AI.\n", "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n", "Human: Tell me about yourself.\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers.\""]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"Tell me about yourself.\")"]}, {"cell_type": "markdown", "id": "bd0146c2", "metadata": {}, "source": ["\u8fd9\u5c31\u662f\u5165\u95e8\u7684\u5168\u90e8\u5185\u5bb9\uff01\u6709\u8bb8\u591a\u4e0d\u540c\u7c7b\u578b\u7684\u5b58\u50a8\u5668\uff0c\u8bf7\u67e5\u770b\u6211\u4eec\u7684\u793a\u4f8b\u4ee5\u4e86\u89e3\u5b83\u4eec\u5168\u90e8\u3002"]}, {"cell_type": "code", "execution_count": null, "id": "447c138d", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}