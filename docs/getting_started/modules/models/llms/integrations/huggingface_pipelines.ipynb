{"cells": [{"cell_type": "markdown", "id": "959300d4", "metadata": {}, "source": ["# Hugging Face Pipeline\n", "\n", "\u4f7f\u7528Hugging Face Pipeline\n", "\n", "[Hugging Face\u6a21\u578b\u4e2d\u5fc3](https://huggingface.co/models)\u6258\u7ba1\u4e86\u8d85\u8fc7120k\u4e2a\u6a21\u578b\u300120k\u6570\u636e\u96c6\u548c50k\u4e2a\u6f14\u793a\u5e94\u7528\uff08Spaces\uff09\uff0c\u5168\u90e8\u90fd\u662f\u5f00\u6e90\u7684\u5e76\u4e14\u516c\u5f00\u53ef\u7528\u3002\u8fd9\u4e2a\u5728\u7ebf\u5e73\u53f0\u8ba9\u4eba\u4eec\u53ef\u4ee5\u8f7b\u677e\u534f\u4f5c\u3001\u5171\u540c\u6784\u5efa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u53ef\u4ee5\u901a\u8fc7\u672c\u5730Pipeline\u5305\u88c5\u5668\u6216\u8005\u901a\u8fc7HuggingFaceHub\u7c7b\u8c03\u7528\u6258\u7ba1\u7684\u63a8\u7406\u7ec8\u7aef\u6765\u8c03\u7528\u5b83\u4eec\uff0c\u4ee5\u6b64\u6765\u5728LangChain\u4e2d\u4f7f\u7528\u5b83\u4eec\u3002\u6709\u5173\u6258\u7ba1\u7684Pipeline\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605[HuggingFaceHub](huggingface_hub.ipynb)\u7b14\u8bb0\u672c\u3002"]}, {"cell_type": "markdown", "id": "4c1b8450-5eaf-4d34-8341-2d785448a1ff", "metadata": {"tags": []}, "source": ["\u4f7f\u7528\u524d\uff0c\u60a8\u5e94\u8be5\u5b89\u88c5``transformers`` Python [\u5305](https://pypi.org/project/transformers/)\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "d772b637-de00-4663-bd77-9bc96d798db2", "metadata": {"tags": []}, "outputs": [], "source": ["!pip install transformers > /dev/null"]}, {"cell_type": "markdown", "id": "91ad075f-71d5-4bc8-ab91-cc0ad5ef16bb", "metadata": {}, "source": ["### \u52a0\u8f7d\u6a21\u578b"]}, {"cell_type": "code", "execution_count": 2, "id": "165ae236-962a-4763-8052-c4836d78a5d2", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["WARNING:root:Failed to default session, using empty session: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sessions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1117f9790>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"]}], "source": ["from langchain import HuggingFacePipeline\n", "\n", "llm = HuggingFacePipeline.from_model_id(model_id=\"bigscience/bloom-1b7\", task=\"text-generation\", model_kwargs={\"temperature\":0, \"max_length\":64})"]}, {"cell_type": "markdown", "id": "00104b27-0c15-4a97-b198-4512337ee211", "metadata": {}, "source": ["### \u5c06\u6a21\u578b\u6574\u5408\u5230LLMChain\u4e2d"]}, {"cell_type": "code", "execution_count": 3, "id": "3acf0069", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/Users/wfh/code/lc/lckg/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n", "  warnings.warn(\n", "WARNING:root:Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x144d06910>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"]}, {"name": "stdout", "output_type": "stream", "text": [" First, we need to understand what is an electroencephalogram. An electroencephalogram is a recording of brain activity. It is a recording of brain activity that is made by placing electrodes on the scalp. The electrodes are placed\n"]}], "source": ["from langchain import PromptTemplate,  LLMChain\n", "\n", "template = \"\"\"Question: {question}\n", "\n", "Answer: Let's think step by step.\"\"\"\n", "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n", "\n", "llm_chain = LLMChain(prompt=prompt, llm=llm)\n", "\n", "question = \"What is electroencephalography?\"\n", "\n", "print(llm_chain.run(question))"]}, {"cell_type": "code", "execution_count": null, "id": "843a3837", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.6"}}, "nbformat": 4, "nbformat_minor": 5}