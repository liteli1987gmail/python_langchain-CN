{"cells": [{"cell_type": "markdown", "id": "cbe47c3a", "metadata": {}, "source": ["# \u5e8f\u5217\u5316\n", "\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u5c06\u94fe\u5e8f\u5217\u5316\u5230\u78c1\u76d8\u5e76\u4ece\u78c1\u76d8\u4e2d\u8bfb\u53d6\u5e8f\u5217\u5316\u7684\u94fe\u3002\u6211\u4eec\u4f7f\u7528\u7684\u5e8f\u5217\u5316\u683c\u5f0f\u662fjson\u6216yaml\u3002\u5f53\u524d\uff0c\u53ea\u6709\u4e00\u4e9b\u94fe\u652f\u6301\u6b64\u7c7b\u578b\u7684\u5e8f\u5217\u5316\u3002\u6211\u4eec\u5c06\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u6269\u5927\u652f\u6301\u7684\u94fe\u7684\u6570\u91cf\u3002\n"]}, {"cell_type": "markdown", "id": "e4a8a447", "metadata": {}, "source": ["## \u5c06\u94fe\u4fdd\u5b58\u5230\u78c1\u76d8\n", "\u9996\u5148\uff0c\u8ba9\u6211\u4eec\u8ba8\u8bba\u5982\u4f55\u5c06\u94fe\u4fdd\u5b58\u5230\u78c1\u76d8\u3002\u8fd9\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528`.save`\u65b9\u6cd5\u5e76\u6307\u5b9a\u5e26\u6709json\u6216yaml\u6269\u5c55\u540d\u7684\u6587\u4ef6\u8def\u5f84\u6765\u5b8c\u6210\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "26e28451", "metadata": {}, "outputs": [], "source": ["from langchain import PromptTemplate, OpenAI, LLMChain\n", "template = \"\"\"Question: {question}\n", "\n", "Answer: Let's think step by step.\"\"\"\n", "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n", "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0), verbose=True)\n"]}, {"cell_type": "code", "execution_count": 2, "id": "bfa18e1f", "metadata": {}, "outputs": [], "source": ["llm_chain.save(\"llm_chain.json\")"]}, {"cell_type": "markdown", "id": "ea82665d", "metadata": {}, "source": ["\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u6765\u770b\u770b\u4fdd\u5b58\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9\u3002"]}, {"cell_type": "code", "execution_count": 3, "id": "0fd33328", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\r\n", "    \"memory\": null,\r\n", "    \"verbose\": true,\r\n", "    \"prompt\": {\r\n", "        \"input_variables\": [\r\n", "            \"question\"\r\n", "        ],\r\n", "        \"output_parser\": null,\r\n", "        \"template\": \"Question: {question}\\n\\nAnswer: Let's think step by step.\",\r\n", "        \"template_format\": \"f-string\"\r\n", "    },\r\n", "    \"llm\": {\r\n", "        \"model_name\": \"text-davinci-003\",\r\n", "        \"temperature\": 0.0,\r\n", "        \"max_tokens\": 256,\r\n", "        \"top_p\": 1,\r\n", "        \"frequency_penalty\": 0,\r\n", "        \"presence_penalty\": 0,\r\n", "        \"n\": 1,\r\n", "        \"best_of\": 1,\r\n", "        \"request_timeout\": null,\r\n", "        \"logit_bias\": {},\r\n", "        \"_type\": \"openai\"\r\n", "    },\r\n", "    \"output_key\": \"text\",\r\n", "    \"_type\": \"llm_chain\"\r\n", "}"]}], "source": ["!cat llm_chain.json"]}, {"cell_type": "markdown", "id": "2012c724", "metadata": {}, "source": ["## \u4ece\u78c1\u76d8\u52a0\u8f7d\u94fe\n", "\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528`load_chain`\u65b9\u6cd5\u4ece\u78c1\u76d8\u52a0\u8f7d\u94fe\u3002"]}, {"cell_type": "code", "execution_count": 4, "id": "342a1974", "metadata": {}, "outputs": [], "source": ["from langchain.chains import load_chain"]}, {"cell_type": "code", "execution_count": 5, "id": "394b7da8", "metadata": {}, "outputs": [], "source": ["chain = load_chain(\"llm_chain.json\")"]}, {"cell_type": "code", "execution_count": 6, "id": "20d99787", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mQuestion: whats 2 + 2\n", "\n", "Answer: Let's think step by step.\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["' 2 + 2 = 4'"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["chain.run(\"whats 2 + 2\")"]}, {"cell_type": "markdown", "id": "14449679", "metadata": {}, "source": ["## \u5206\u522b\u4fdd\u5b58\u7ec4\u4ef6\n", "\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u63d0\u793a\u7b26\u548cllm\u914d\u7f6e\u4fe1\u606f\u4fdd\u5b58\u5728\u4e0e\u6574\u4e2a\u94fe\u76f8\u540c\u7684json\u4e2d\u3002\u6216\u8005\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5b83\u4eec\u5206\u5f00\u4fdd\u5b58\u3002\u8fd9\u7ecf\u5e38\u6709\u7528\uff0c\u53ef\u4ee5\u4f7f\u4fdd\u5b58\u7684\u7ec4\u4ef6\u66f4\u52a0\u6a21\u5757\u5316\u3002\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ea\u9700\u8981\u6307\u5b9a`llm_path`\u800c\u4e0d\u662f`llm`\u7ec4\u4ef6\uff0c\u4ee5\u53ca`prompt_path`\u800c\u4e0d\u662f`prompt`\u7ec4\u4ef6\u3002"]}, {"cell_type": "code", "execution_count": 7, "id": "50ec35ab", "metadata": {}, "outputs": [], "source": ["llm_chain.prompt.save(\"prompt.json\")"]}, {"cell_type": "code", "execution_count": 8, "id": "c48b39aa", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\r\n", "    \"input_variables\": [\r\n", "        \"question\"\r\n", "    ],\r\n", "    \"output_parser\": null,\r\n", "    \"template\": \"Question: {question}\\n\\nAnswer: Let's think step by step.\",\r\n", "    \"template_format\": \"f-string\"\r\n", "}"]}], "source": ["!cat prompt.json"]}, {"cell_type": "code", "execution_count": 9, "id": "13c92944", "metadata": {}, "outputs": [], "source": ["llm_chain.llm.save(\"llm.json\")"]}, {"cell_type": "code", "execution_count": 10, "id": "1b815f89", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\r\n", "    \"model_name\": \"text-davinci-003\",\r\n", "    \"temperature\": 0.0,\r\n", "    \"max_tokens\": 256,\r\n", "    \"top_p\": 1,\r\n", "    \"frequency_penalty\": 0,\r\n", "    \"presence_penalty\": 0,\r\n", "    \"n\": 1,\r\n", "    \"best_of\": 1,\r\n", "    \"request_timeout\": null,\r\n", "    \"logit_bias\": {},\r\n", "    \"_type\": \"openai\"\r\n", "}"]}], "source": ["!cat llm.json"]}, {"cell_type": "code", "execution_count": 11, "id": "7e6aa9ab", "metadata": {}, "outputs": [], "source": ["config = {\n", "    \"memory\": None,\n", "    \"verbose\": True,\n", "    \"prompt_path\": \"prompt.json\",\n", "    \"llm_path\": \"llm.json\",\n", "    \"output_key\": \"text\",\n", "    \"_type\": \"llm_chain\"\n", "}\n", "import json\n", "with open(\"llm_chain_separate.json\", \"w\") as f:\n", "    json.dump(config, f, indent=2)"]}, {"cell_type": "code", "execution_count": 12, "id": "8e959ca6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\r\n", "  \"memory\": null,\r\n", "  \"verbose\": true,\r\n", "  \"prompt_path\": \"prompt.json\",\r\n", "  \"llm_path\": \"llm.json\",\r\n", "  \"output_key\": \"text\",\r\n", "  \"_type\": \"llm_chain\"\r\n", "}"]}], "source": ["!cat llm_chain_separate.json"]}, {"cell_type": "markdown", "id": "662731c0", "metadata": {}, "source": ["\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4ee5\u540c\u6837\u7684\u65b9\u5f0f\u52a0\u8f7d\u5b83\u3002"]}, {"cell_type": "code", "execution_count": 13, "id": "d69ceb93", "metadata": {}, "outputs": [], "source": ["chain = load_chain(\"llm_chain_separate.json\")"]}, {"cell_type": "code", "execution_count": 15, "id": "a99d61b9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mQuestion: whats 2 + 2\n", "\n", "Answer: Let's think step by step.\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["' 2 + 2 = 4'"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["chain.run(\"whats 2 + 2\")"]}, {"cell_type": "code", "execution_count": null, "id": "822b7c12", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.9"}}, "nbformat": 4, "nbformat_minor": 5}