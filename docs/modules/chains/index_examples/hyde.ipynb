{"cells": [{"cell_type": "markdown", "id": "ccb74c9b", "metadata": {}, "source": ["# \u5047\u8bbe\u6587\u6863\u5d4c\u5165\n", "\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528\u5047\u8bbe\u6587\u6863\u5d4c\u5165\uff08HyDE\uff09\uff0c\u5177\u4f53\u5185\u5bb9\u53c2\u89c1[\u8fd9\u7bc7\u8bba\u6587](https://arxiv.org/abs/2212.10496)\u3002\n", "\n", "\u5728\u9ad8\u5c42\u6b21\u4e0a\uff0cHyDE\u662f\u4e00\u79cd\u5d4c\u5165\u6280\u672f\uff0c\u5b83\u63a5\u53d7\u67e5\u8be2\uff0c\u751f\u6210\u4e00\u4e2a\u5047\u8bbe\u7684\u7b54\u6848\uff0c\u7136\u540e\u5d4c\u5165\u751f\u6210\u7684\u6587\u6863\u5e76\u5c06\u5176\u4f5c\u4e3a\u6700\u7ec8\u793a\u4f8b\u4f7f\u7528\u3002\n", "\n", "\u56e0\u6b64\uff0c\u8981\u4f7f\u7528HyDE\uff0c\u6211\u4eec\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u57fa\u672c\u7684\u5d4c\u5165\u6a21\u578b\u4ee5\u53ca\u4e00\u6761\u80fd\u591f\u7528\u4e8e\u751f\u6210\u8fd9\u4e9b\u6587\u6863\u7684LLMChain\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cHyDE\u7c7b\u5e26\u6709\u4e00\u4e9b\u9ed8\u8ba4\u63d0\u793a\uff08\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u8bba\u6587\uff09\uff0c\u4f46\u662f\u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u81ea\u5df1\u7684\u63d0\u793a\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "546e87ee", "metadata": {}, "outputs": [], "source": ["from langchain.llms import OpenAI\n", "from langchain.embeddings import OpenAIEmbeddings\n", "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n", "from langchain.prompts import PromptTemplate"]}, {"cell_type": "code", "execution_count": 2, "id": "c0ea895f", "metadata": {}, "outputs": [], "source": ["base_embeddings = OpenAIEmbeddings()\n", "llm = OpenAI()"]}, {"cell_type": "markdown", "id": "33bd6905", "metadata": {}, "source": []}, {"cell_type": "code", "execution_count": 3, "id": "50729989", "metadata": {}, "outputs": [], "source": ["# Load with `web_search` prompt\n", "embeddings = HypotheticalDocumentEmbedder.from_llm(llm, base_embeddings, \"web_search\")"]}, {"cell_type": "code", "execution_count": 4, "id": "3aa573d6", "metadata": {}, "outputs": [], "source": ["# Now we can use it as any embedding class!\n", "result = embeddings.embed_query(\"Where is the Taj Mahal?\")"]}, {"cell_type": "markdown", "id": "c7a0b556", "metadata": {}, "source": ["## \u591a\u4e2a\u751f\u6210\n", "\u6211\u4eec\u8fd8\u53ef\u4ee5\u751f\u6210\u591a\u4e2a\u6587\u6863\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u5d4c\u5165\u8fdb\u884c\u7ec4\u5408\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u901a\u8fc7\u53d6\u5e73\u5747\u503c\u6765\u7ec4\u5408\u8fd9\u4e9b\u5d4c\u5165\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u66f4\u6539\u7528\u4e8e\u751f\u6210\u6587\u6863\u7684LLM\u6765\u6267\u884c\u6b64\u64cd\u4f5c\u3002"]}, {"cell_type": "code", "execution_count": 5, "id": "05da7060", "metadata": {}, "outputs": [], "source": ["multi_llm = OpenAI(n=4, best_of=4)"]}, {"cell_type": "code", "execution_count": 6, "id": "9b1e12bd", "metadata": {}, "outputs": [], "source": ["embeddings = HypotheticalDocumentEmbedder.from_llm(multi_llm, base_embeddings, \"web_search\")"]}, {"cell_type": "code", "execution_count": 7, "id": "a60cd343", "metadata": {}, "outputs": [], "source": ["result = embeddings.embed_query(\"Where is the Taj Mahal?\")"]}, {"cell_type": "markdown", "id": "1da90437", "metadata": {}, "source": ["## \u4f7f\u7528\u6211\u4eec\u81ea\u5df1\u7684\u63d0\u793a\n", "\u9664\u4e86\u4f7f\u7528\u9884\u914d\u7f6e\u7684\u63d0\u793a\u5916\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u8f7b\u677e\u6784\u5efa\u81ea\u5df1\u7684\u63d0\u793a\u5e76\u5c06\u5176\u7528\u4e8e\u751f\u6210\u6587\u6863\u7684LLMChain\u4e2d\u3002\u5982\u679c\u6211\u4eec\u77e5\u9053\u67e5\u8be2\u6240\u5728\u7684\u57df\uff0c\u8fd9\u53ef\u80fd\u975e\u5e38\u6709\u7528\uff0c\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u5c06\u63d0\u793a\u7684\u6761\u4ef6\u8c03\u6574\u4e3a\u751f\u6210\u66f4\u7c7b\u4f3c\u8be5\u57df\u7684\u6587\u672c\u3002\n", "\n", "\u5728\u4e0b\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u8ba9\u6211\u4eec\u5c06\u5176\u6761\u4ef6\u4e3a\u751f\u6210\u6709\u5173\u8054\u90a6\u6f14\u8bb2\u7684\u6587\u672c\uff08\u56e0\u4e3a\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u4e2a\u793a\u4f8b\u4e2d\u4f7f\u7528\u5b83\uff09"]}, {"cell_type": "code", "execution_count": 8, "id": "0b4a650f", "metadata": {}, "outputs": [], "source": ["prompt_template = \"\"\"Please answer the user's question about the most recent state of the union address\n", "Question: {question}\n", "Answer:\"\"\"\n", "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n", "llm_chain = LLMChain(llm=llm, prompt=prompt)"]}, {"cell_type": "code", "execution_count": 9, "id": "7f7e2b86", "metadata": {}, "outputs": [], "source": ["embeddings = HypotheticalDocumentEmbedder(llm_chain=llm_chain, base_embeddings=base_embeddings)"]}, {"cell_type": "code", "execution_count": 10, "id": "6dd83424", "metadata": {}, "outputs": [], "source": ["result = embeddings.embed_query(\"What did the president say about Ketanji Brown Jackson\")"]}, {"cell_type": "markdown", "id": "31388123", "metadata": {}, "source": ["## \u4f7f\u7528HyDE\n", "\u65e2\u7136\u6211\u4eec\u6709\u4e86HyDE\uff0c\u6211\u4eec\u53ef\u4ee5\u50cf\u4f7f\u7528\u4efb\u4f55\u5176\u4ed6\u5d4c\u5165\u7c7b\u4e00\u6837\u4f7f\u7528\u5b83\uff01\u4ee5\u4e0b\u662f\u5728\u56fd\u60c5\u54a8\u6587\u793a\u4f8b\u4e2d\u4f7f\u7528\u5b83\u4ee5\u67e5\u627e\u7c7b\u4f3c\u6bb5\u843d\u7684\u793a\u4f8b\u3002"]}, {"cell_type": "code", "execution_count": 11, "id": "97719b29", "metadata": {}, "outputs": [], "source": ["from langchain.text_splitter import CharacterTextSplitter\n", "from langchain.vectorstores import Chroma\n", "\n", "with open(\"../../state_of_the_union.txt\") as f:\n", "    state_of_the_union = f.read()\n", "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n", "texts = text_splitter.split_text(state_of_the_union)"]}, {"cell_type": "code", "execution_count": 12, "id": "bfcfc039", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Running Chroma using direct local API.\n", "Using DuckDB in-memory for database. Data will be transient.\n"]}], "source": ["docsearch = Chroma.from_texts(texts, embeddings)\n", "\n", "query = \"What did the president say about Ketanji Brown Jackson\"\n", "docs = docsearch.similarity_search(query)"]}, {"cell_type": "code", "execution_count": 13, "id": "632af7f2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["In state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n", "\n", "We cannot let this happen. \n", "\n", "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n", "\n", "Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n", "\n", "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n", "\n", "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n"]}], "source": ["print(docs[0].page_content)"]}, {"cell_type": "code", "execution_count": null, "id": "b9e57b93", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}, "vscode": {"interpreter": {"hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}}, "nbformat": 4, "nbformat_minor": 5}