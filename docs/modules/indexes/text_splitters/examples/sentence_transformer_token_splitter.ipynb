{"cells": [{"cell_type": "markdown", "id": "73dbcdb9", "metadata": {}, "source": ["# SentenceTransformersTokenTextSplitter\n", "\n", "\u8fd9\u4e2a\u7b14\u8bb0\u672c\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528`SentenceTransformersTokenTextSplitter`\u6587\u672c\u5206\u5272\u5668\u3002\n", "\n", "\u8bed\u8a00\u6a21\u578b\u6709\u4e00\u4e2a\u4ee4\u724c\u9650\u5236\u3002\u4e0d\u5e94\u8d85\u8fc7\u4ee4\u724c\u9650\u5236\u3002\u5f53\u60a8\u5c06\u6587\u672c\u5206\u6210\u5757\u65f6\uff0c\u7edf\u8ba1\u4ee4\u724c\u6570\u662f\u4e00\u4e2a\u597d\u4e3b\u610f\u3002\u6709\u8bb8\u591a\u4ee4\u724c\u5316\u5668\u3002\u5728\u6587\u672c\u4e2d\u7edf\u8ba1\u4ee4\u724c\u6570\u65f6\uff0c\u60a8\u5e94\u4f7f\u7528\u4e0e\u8bed\u8a00\u6a21\u578b\u4e2d\u4f7f\u7528\u7684\u76f8\u540c\u7684\u4ee4\u724c\u5316\u5668\u3002\n", "\n", "`SentenceTransformersTokenTextSplitter`\u662f\u7528\u4e8e\u53e5\u5b50\u8f6c\u6362\u5668\u6a21\u578b\u7684\u4e13\u7528\u6587\u672c\u5206\u5272\u5668\u3002\u9ed8\u8ba4\u884c\u4e3a\u662f\u5c06\u6587\u672c\u5206\u6210\u9002\u5408\u60a8\u60f3\u8981\u4f7f\u7528\u7684\u53e5\u5b50\u8f6c\u6362\u5668\u6a21\u578b\u7684\u4ee4\u724c\u7a97\u53e3\u7684\u5757\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "9dd5419e", "metadata": {}, "outputs": [], "source": ["from langchain.text_splitter import SentenceTransformersTokenTextSplitter"]}, {"cell_type": "code", "execution_count": 2, "id": "b43e5d54", "metadata": {}, "outputs": [], "source": ["splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0)\n", "text = \"Lorem \""]}, {"cell_type": "code", "execution_count": 3, "id": "1df84cb4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["2\n"]}], "source": ["count_start_and_stop_tokens = 2\n", "text_token_count = splitter.count_tokens(text=text) - count_start_and_stop_tokens\n", "print(text_token_count)"]}, {"cell_type": "code", "execution_count": 4, "id": "d7ad2213", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tokens in text to split: 514\n"]}], "source": ["token_multiplier = splitter.maximum_tokens_per_chunk // text_token_count + 1\n", "\n", "# `text_to_split` does not fit in a single chunk\n", "text_to_split = text * token_multiplier\n", "\n", "print(f\"tokens in text to split: {splitter.count_tokens(text=text_to_split)}\")"]}, {"cell_type": "code", "execution_count": 5, "id": "818aea04", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["lorem\n"]}], "source": ["text_chunks = splitter.split_text(text=text_to_split)\n", "\n", "print(text_chunks[1])"]}, {"cell_type": "code", "execution_count": null, "id": "e9ba4f23", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}