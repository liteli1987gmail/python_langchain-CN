{"cells": [{"cell_type": "markdown", "id": "44c9933a", "metadata": {}, "source": ["# \u5bf9\u8bdd\u77e5\u8bc6\u56fe\u5fc6", "\n", "\u8fd9\u79cd\u7c7b\u578b\u7684\u5fc6\u4f7f\u7528\u77e5\u8bc6\u56fe\u6765\u91cd\u73b0\u8bb0\u5fc6\u3002", "\n", "\u8ba9\u6211\u4eec\u5148\u8d70\u4e00\u904d\u5982\u4f55\u4f7f\u7528\u5b9e\u7528\u7a0b\u5e8f"]}, {"cell_type": "code", "execution_count": 1, "id": "f71f40ba", "metadata": {}, "outputs": [], "source": ["from langchain.memory import ConversationKGMemory\n", "from langchain.llms import OpenAI"]}, {"cell_type": "code", "execution_count": 2, "id": "2f4a3c85", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(temperature=0)\n", "memory = ConversationKGMemory(llm=llm)\n", "memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n", "memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})"]}, {"cell_type": "code", "execution_count": 3, "id": "72283b4f", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'On Sam: Sam is friend.'}"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({\"input\": 'who is sam'})"]}, {"cell_type": "markdown", "id": "0c8ff11e", "metadata": {}, "source": ["\u6211\u4eec\u4e5f\u53ef\u4ee5\u5f97\u5230\u5386\u53f2\u6d88\u606f\u5217\u8868\uff08\u5982\u679c\u60a8\u6b63\u5728\u4e0e\u804a\u5929\u6a21\u578b\u4e00\u8d77\u4f7f\u7528\u5b83\uff0c\u5219\u8fd9\u662f\u6709\u7528\u7684\uff09\u3002"]}, {"cell_type": "code", "execution_count": 4, "id": "44df43af", "metadata": {}, "outputs": [], "source": ["memory = ConversationKGMemory(llm=llm, return_messages=True)\n", "memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n", "memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})"]}, {"cell_type": "code", "execution_count": 5, "id": "4726b1c8", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': [SystemMessage(content='On Sam: Sam is friend.', additional_kwargs={})]}"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({\"input\": 'who is sam'})"]}, {"cell_type": "markdown", "id": "dc956b0e", "metadata": {}, "source": ["\u6211\u4eec\u4e5f\u53ef\u4ee5\u66f4\u6a21\u5757\u5316\u5730\u4ece\u65b0\u6d88\u606f\u4e2d\u83b7\u53d6\u5f53\u524d\u5b9e\u4f53\uff08\u5c06\u4f7f\u7528\u5148\u524d\u7684\u6d88\u606f\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff09\u3002"]}, {"cell_type": "code", "execution_count": 9, "id": "36331ca5", "metadata": {}, "outputs": [{"data": {"text/plain": ["['Sam']"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.get_current_entities(\"what's Sams favorite color?\")"]}, {"cell_type": "markdown", "id": "e8749134", "metadata": {}, "source": ["\u6211\u4eec\u8fd8\u53ef\u4ee5\u66f4\u6a21\u5757\u5316\u5730\u4ece\u65b0\u6d88\u606f\u4e2d\u83b7\u53d6\u77e5\u8bc6\u4e09\u5143\u7ec4\uff08\u5c06\u4f7f\u7528\u5148\u524d\u7684\u6d88\u606f\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff09\u3002"]}, {"cell_type": "code", "execution_count": 10, "id": "b02d44db", "metadata": {}, "outputs": [{"data": {"text/plain": ["[KnowledgeTriple(subject='Sam', predicate='favorite color', object_='red')]"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.get_knowledge_triplets(\"her favorite color is red\")"]}, {"cell_type": "markdown", "id": "f7a02ef3", "metadata": {}, "source": ["## \u5728\u94fe\u4e2d\u4f7f\u7528", "\u73b0\u5728\u8ba9\u6211\u4eec\u5728\u94fe\u4e2d\u4f7f\u7528\u5b83\uff01"]}, {"cell_type": "code", "execution_count": 7, "id": "b462baf1", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(temperature=0)\n", "from langchain.prompts.prompt import PromptTemplate\n", "from langchain.chains import ConversationChain\n", "\n", "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n", "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n", "\n", "Relevant Information:\n", "\n", "{history}\n", "\n", "Conversation:\n", "Human: {input}\n", "AI:\"\"\"\n", "prompt = PromptTemplate(\n", "    input_variables=[\"history\", \"input\"], template=template\n", ")\n", "conversation_with_kg = ConversationChain(\n", "    llm=llm, \n", "    verbose=True, \n", "    prompt=prompt,\n", "    memory=ConversationKGMemory(llm=llm)\n", ")"]}, {"cell_type": "code", "execution_count": 8, "id": "97efaf38", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n", "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n", "\n", "Relevant Information:\n", "\n", "\n", "\n", "Conversation:\n", "Human: Hi, what's up?\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" Hi there! I'm doing great. I'm currently in the process of learning about the world around me. I'm learning about different cultures, languages, and customs. It's really fascinating! How about you?\""]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation_with_kg.predict(input=\"Hi, what's up?\")"]}, {"cell_type": "code", "execution_count": 9, "id": "55b5bcad", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n", "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n", "\n", "Relevant Information:\n", "\n", "\n", "\n", "Conversation:\n", "Human: My name is James and I'm helping Will. He's an engineer.\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\" Hi James, it's nice to meet you. I'm an AI and I understand you're helping Will, the engineer. What kind of engineering does he do?\""]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation_with_kg.predict(input=\"My name is James and I'm helping Will. He's an engineer.\")"]}, {"cell_type": "code", "execution_count": 10, "id": "9981e219", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n", "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n", "\n", "Relevant Information:\n", "\n", "On Will: Will is an engineer.\n", "\n", "Conversation:\n", "Human: What do you know about Will?\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["' Will is an engineer.'"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation_with_kg.predict(input=\"What do you know about Will?\")"]}, {"cell_type": "code", "execution_count": null, "id": "8c09a239", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}