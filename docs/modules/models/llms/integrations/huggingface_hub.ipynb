{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "959300d4", "metadata": {}, "source": ["# Hugging Face Hub\n", "\n", "\u56de\u62e5\u62b1\u9762\u5b54\u4e2d\u5fc3\uff08Hugging Face Hub\uff09\n", "\n", "[Hugging Face Hub](https://huggingface.co/docs/hub/index) \u662f\u4e00\u4e2a\u62e5\u6709\u8d85\u8fc712\u4e07\u4e2a\u6a21\u578b\u30012\u4e07\u4e2a\u6570\u636e\u96c6\u548c5\u4e07\u4e2a\u6f14\u793a\u5e94\u7528\uff08\u7a7a\u95f4\uff09\u7684\u5e73\u53f0\uff0c\u6240\u6709\u5185\u5bb9\u90fd\u662f\u5f00\u6e90\u548c\u516c\u5f00\u53ef\u7528\u7684\uff0c\u4eba\u4eec\u53ef\u4ee5\u5728\u8fd9\u4e2a\u5728\u7ebf\u5e73\u53f0\u4e0a\u8f7b\u677e\u5408\u4f5c\u548c\u5efa\u7acbML\u3002\n", "\n", "\u672c\u793a\u4f8b\u5c55\u793a\u5982\u4f55\u8fde\u63a5\u5230Hugging Face Hub\u3002"]}, {"attachments": {}, "cell_type": "markdown", "id": "4c1b8450-5eaf-4d34-8341-2d785448a1ff", "metadata": {"tags": []}, "source": ["\u8981\u4f7f\u7528\u5b83\uff0c\u60a8\u5e94\u8be5\u5b89\u88c5``huggingface_hub`` python[Package installed](https://huggingface.co/docs/huggingface_hub/installation)\u3002"]}, {"cell_type": "code", "execution_count": null, "id": "d772b637-de00-4663-bd77-9bc96d798db2", "metadata": {"tags": []}, "outputs": [], "source": ["!pip install huggingface_hub > /dev/null"]}, {"cell_type": "code", "execution_count": null, "id": "d597a792-354c-4ca5-b483-5965eec5d63d", "metadata": {}, "outputs": [], "source": ["# get a token: https://huggingface.co/docs/api-inference/quicktour#get-your-api-token\n", "\n", "from getpass import getpass\n", "\n", "HUGGINGFACEHUB_API_TOKEN = getpass()"]}, {"cell_type": "code", "execution_count": null, "id": "b8c5b88c-e4b8-4d0d-9a35-6e8f106452c2", "metadata": {}, "outputs": [], "source": ["import os\n", "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"]}, {"attachments": {}, "cell_type": "markdown", "id": "84dd44c1-c428-41f3-a911-520281386c94", "metadata": {}, "source": ["**\u9009\u62e9\u4e00\u4e2a\u6a21\u578b**"]}, {"cell_type": "code", "execution_count": null, "id": "39c7eeac-01c4-486b-9480-e828a9e73e78", "metadata": {"tags": []}, "outputs": [], "source": ["from langchain import HuggingFaceHub\n", "\n", "repo_id = \"google/flan-t5-xl\" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n", "\n", "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":0, \"max_length\":64})"]}, {"cell_type": "code", "execution_count": null, "id": "3acf0069", "metadata": {}, "outputs": [], "source": ["from langchain import PromptTemplate, LLMChain\n", "\n", "template = \"\"\"Question: {question}\n", "\n", "Answer: Let's think step by step.\"\"\"\n", "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n", "llm_chain = LLMChain(prompt=prompt, llm=llm)\n", "\n", "question = \"Who won the FIFA World Cup in the year 1994? \"\n", "\n", "print(llm_chain.run(question))"]}, {"attachments": {}, "cell_type": "markdown", "id": "ddaa06cf-95ec-48ce-b0ab-d892a7909693", "metadata": {}, "source": ["## Examples\n", "\n", "\u4ee5\u4e0b\u662f\u901a\u8fc7Hugging Face Hub\u96c6\u6210\u8bbf\u95ee\u7684\u4e00\u4e9b\u6a21\u578b\u793a\u4f8b\u3002"]}, {"attachments": {}, "cell_type": "markdown", "id": "4fa9337e-ccb5-4c52-9b7c-1653148bc256", "metadata": {}, "source": ["### StableLM, by Stability AI\n", "\n", "\u67e5\u770b[Stability AI](https://huggingface.co/stabilityai)\u7ec4\u7ec7\u9875\u9762\uff0c\u4e86\u89e3\u53ef\u7528\u6a21\u578b\u7684\u5217\u8868\u3002"]}, {"cell_type": "code", "execution_count": null, "id": "36a1ce01-bd46-451f-8ee6-61c8f4bd665a", "metadata": {}, "outputs": [], "source": ["repo_id = \"stabilityai/stablelm-tuned-alpha-3b\"\n", "# Others include stabilityai/stablelm-base-alpha-3b\n", "# as well as 7B parameter versions"]}, {"cell_type": "code", "execution_count": null, "id": "b5654cea-60b0-4f40-ab34-06ba1eca810d", "metadata": {}, "outputs": [], "source": ["llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":0, \"max_length\":64})"]}, {"cell_type": "code", "execution_count": null, "id": "2f19d0dc-c987-433f-a8d6-b1214e8ee067", "metadata": {}, "outputs": [], "source": ["# Reuse the prompt and question from above.\n", "llm_chain = LLMChain(prompt=prompt, llm=llm)\n", "print(llm_chain.run(question))"]}, {"attachments": {}, "cell_type": "markdown", "id": "1a5c97af-89bc-4e59-95c1-223742a9160b", "metadata": {}, "source": ["### Dolly, by Databricks\n", "\n", "\u8bf7\u53c2\u9605[Databricks](https://huggingface.co/databricks)\u7ec4\u7ec7\u9875\u9762\uff0c\u4e86\u89e3\u53ef\u7528\u6a21\u578b\u7684\u5217\u8868\u3002"]}, {"cell_type": "code", "execution_count": null, "id": "521fcd2b-8e38-4920-b407-5c7d330411c9", "metadata": {}, "outputs": [], "source": ["from langchain import HuggingFaceHub\n", "\n", "repo_id = \"databricks/dolly-v2-3b\"\n", "\n", "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":0, \"max_length\":64})"]}, {"cell_type": "code", "execution_count": null, "id": "9907ec3a-fe0c-4543-81c4-d42f9453f16c", "metadata": {"tags": []}, "outputs": [], "source": ["# Reuse the prompt and question from above.\n", "llm_chain = LLMChain(prompt=prompt, llm=llm)\n", "print(llm_chain.run(question))"]}, {"attachments": {}, "cell_type": "markdown", "id": "03f6ae52-b5f9-4de6-832c-551cb3fa11ae", "metadata": {}, "source": ["### Camel, by Writer\n", "\n", "\u8bf7\u53c2\u9605[Writer](https://huggingface.co/Writer)\u7ec4\u7ec7\u9875\u9762\uff0c\u4e86\u89e3\u53ef\u7528\u6a21\u578b\u7684\u5217\u8868\u3002"]}, {"cell_type": "code", "execution_count": null, "id": "257a091d-750b-4910-ac08-fe1c7b3fd98b", "metadata": {"tags": []}, "outputs": [], "source": ["from langchain import HuggingFaceHub\n", "\n", "repo_id = \"Writer/camel-5b-hf\" # See https://huggingface.co/Writer for other options\n", "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":0, \"max_length\":64})"]}, {"cell_type": "code", "execution_count": null, "id": "b06f6838-a11a-4d6a-88e3-91fa1747a2b3", "metadata": {}, "outputs": [], "source": ["# Reuse the prompt and question from above.\n", "llm_chain = LLMChain(prompt=prompt, llm=llm)\n", "print(llm_chain.run(question))"]}, {"attachments": {}, "cell_type": "markdown", "id": "2bf838eb-1083-402f-b099-b07c452418c8", "metadata": {}, "source": ["**\u8fd8\u6709\u66f4\u591a\uff01**"]}, {"cell_type": "code", "execution_count": null, "id": "18c78880-65d7-41d0-9722-18090efb60e9", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.2"}}, "nbformat": 4, "nbformat_minor": 5}