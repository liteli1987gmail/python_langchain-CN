{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "91871002", "metadata": {}, "source": ["# \u7ed3\u6784\u5316\u8f93\u51fa\u89e3\u6790\u5668\n", "\n", "\u5c3d\u7ba1 Pydantic/JSON \u89e3\u6790\u5668\u66f4\u52a0\u5f3a\u5927\uff0c\u4f46\u6211\u4eec\u6700\u521d\u5c1d\u8bd5\u7684\u6570\u636e\u7ed3\u6784\u4ec5\u5305\u542b\u6587\u672c\u5b57\u6bb5\u3002# Structured Output Parser"]}, {"cell_type": "code", "execution_count": 23, "id": "b492997a", "metadata": {}, "outputs": [], "source": ["from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n", "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n", "from langchain.llms import OpenAI\n", "from langchain.chat_models import ChatOpenAI"]}, {"attachments": {}, "cell_type": "markdown", "id": "09473dce", "metadata": {}, "source": ["\u5728\u8fd9\u91cc\u5b9a\u4e49\u4e86\u6211\u4eec\u60f3\u8981\u63a5\u6536\u7684\u54cd\u5e94\u6a21\u5f0f\u3002Here we define the response schema we want to receive."]}, {"cell_type": "code", "execution_count": 24, "id": "432ac44a", "metadata": {}, "outputs": [], "source": ["response_schemas = [\n", "    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n", "    ResponseSchema(name=\"source\", description=\"source used to answer the user's question, should be a website.\")\n", "]\n", "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"]}, {"attachments": {}, "cell_type": "markdown", "id": "7b92ce96", "metadata": {}, "source": ["\u73b0\u5728\u6211\u4eec\u5f97\u5230\u4e00\u4e2a\u5305\u542b\u54cd\u5e94\u683c\u5f0f\u6307\u4ee4\u7684\u5b57\u7b26\u4e32\uff0c\u7136\u540e\u5c06\u5176\u63d2\u5165\u5230\u6211\u4eec\u7684\u63d0\u793a\u7b26\u4e2d\u3002We now get a string that contains instructions for how the response should be formatted, and we then insert that into our prompt."]}, {"cell_type": "code", "execution_count": 25, "id": "593cfc25", "metadata": {}, "outputs": [], "source": ["format_instructions = output_parser.get_format_instructions()\n", "prompt = PromptTemplate(\n", "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n", "    input_variables=[\"question\"],\n", "    partial_variables={\"format_instructions\": format_instructions}\n", ")"]}, {"attachments": {}, "cell_type": "markdown", "id": "0943e783", "metadata": {}, "source": ["\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e2a\u6765\u683c\u5f0f\u5316\u4e00\u4e2a\u63d0\u793a\u7b26\uff0c\u7136\u540e\u89e3\u6790\u8fd4\u56de\u7684\u7ed3\u679c\u3002We can now use this to format a prompt to send to the language model, and then parse the returned result."]}, {"cell_type": "code", "execution_count": 26, "id": "106f1ba6", "metadata": {}, "outputs": [], "source": ["model = OpenAI(temperature=0)"]}, {"cell_type": "code", "execution_count": 27, "id": "86d9d24f", "metadata": {}, "outputs": [], "source": ["_input = prompt.format_prompt(question=\"what's the capital of france?\")\n", "output = model(_input.to_string())"]}, {"cell_type": "code", "execution_count": 28, "id": "956bdc99", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'answer': 'Paris',\n", " 'source': 'https://www.worldatlas.com/articles/what-is-the-capital-of-france.html'}"]}, "execution_count": 28, "metadata": {}, "output_type": "execute_result"}], "source": ["output_parser.parse(output)"]}, {"attachments": {}, "cell_type": "markdown", "id": "da639285", "metadata": {}, "source": ["\u8fd9\u91cc\u662f\u5728\u804a\u5929\u6a21\u578b\u4e2d\u4f7f\u7528\u5b83\u7684\u4e00\u4e2a\u793a\u4f8b\u3002And here's an example of using this in a chat model"]}, {"cell_type": "code", "execution_count": 29, "id": "8f483d7d", "metadata": {}, "outputs": [], "source": ["chat_model = ChatOpenAI(temperature=0)"]}, {"cell_type": "code", "execution_count": 30, "id": "f761cbf1", "metadata": {}, "outputs": [], "source": ["prompt = ChatPromptTemplate(\n", "    messages=[\n", "        HumanMessagePromptTemplate.from_template(\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\")  \n", "    ],\n", "    input_variables=[\"question\"],\n", "    partial_variables={\"format_instructions\": format_instructions}\n", ")"]}, {"cell_type": "code", "execution_count": 31, "id": "edd73ae3", "metadata": {}, "outputs": [], "source": ["_input = prompt.format_prompt(question=\"what's the capital of france?\")\n", "output = chat_model(_input.to_messages())"]}, {"cell_type": "code", "execution_count": 32, "id": "a3c8b91e", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'answer': 'Paris', 'source': 'https://en.wikipedia.org/wiki/Paris'}"]}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": ["output_parser.parse(output.content)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.11"}}, "nbformat": 4, "nbformat_minor": 5}